{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9eb63f",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973b6764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>insult</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>thomas-frieden</td>\n",
       "      <td>fool</td>\n",
       "      <td>Can you believe this fool, Dr. Thomas Frieden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>thomas-frieden</td>\n",
       "      <td>DOPE</td>\n",
       "      <td>Can you believe this fool, Dr. Thomas Frieden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>politicians</td>\n",
       "      <td>all talk and no action</td>\n",
       "      <td>Big time in U.S. today - MAKE AMERICA GREAT AG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>ben-cardin</td>\n",
       "      <td>It's politicians like Cardin that have destroy...</td>\n",
       "      <td>Politician @SenatorCardin didn't like that I s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>neil-young</td>\n",
       "      <td>total hypocrite</td>\n",
       "      <td>For the nonbeliever, here is a photo of @Neily...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date          target  \\\n",
       "1 2014-10-09  thomas-frieden   \n",
       "2 2014-10-09  thomas-frieden   \n",
       "3 2015-06-16     politicians   \n",
       "4 2015-06-24      ben-cardin   \n",
       "5 2015-06-24      neil-young   \n",
       "\n",
       "                                              insult  \\\n",
       "1                                               fool   \n",
       "2                                               DOPE   \n",
       "3                             all talk and no action   \n",
       "4  It's politicians like Cardin that have destroy...   \n",
       "5                                    total hypocrite   \n",
       "\n",
       "                                               tweet  \n",
       "1  Can you believe this fool, Dr. Thomas Frieden ...  \n",
       "2  Can you believe this fool, Dr. Thomas Frieden ...  \n",
       "3  Big time in U.S. today - MAKE AMERICA GREAT AG...  \n",
       "4  Politician @SenatorCardin didn't like that I s...  \n",
       "5  For the nonbeliever, here is a photo of @Neily...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path for MAC OS\n",
    "t_data = pd.read_csv(r'data/trump_insult_tweets_2014_to_2021.csv',index_col=0)\n",
    "t_data.date = pd.to_datetime(t_data.date)\n",
    "t_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a918d5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      0\n",
       "target    2\n",
       "insult    0\n",
       "tweet     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.isnull().sum() # checking for null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2beb41a",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343ea2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data.dropna(how='any',axis=0,inplace=True) # dropping 2 rows which has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fde09543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      datetime64[ns]\n",
       "target            object\n",
       "insult            object\n",
       "tweet             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.dtypes # checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9115c19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10358, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b80fa4e",
   "metadata": {},
   "source": [
    "## Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea7b6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into 60% - training, 20% - validation, and 20% - testing\n",
    "train_data, test_data = train_test_split(t_data, test_size = 0.2, random_state = 42)\n",
    "\n",
    "train_data, valid_data = train_test_split(train_data, test_size = 0.25, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b3f3300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total examples: 10358\n",
      "Number of training examples: 6214\n",
      "Number of validation examples: 2072\n",
      "Number of testing examples: 2072\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of total examples: {len(t_data)}')\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b64c6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(r'data/train.csv', index = False)\n",
    "test_data.to_csv(r'data/test.csv', index = False)\n",
    "valid_data.to_csv(r'data/valid.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a629ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>insult</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7471</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>Fake News</td>\n",
       "      <td>It’s great to have a wonderful subject, Presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>the-media</td>\n",
       "      <td>biased</td>\n",
       "      <td>Don't believe the biased and phony media quoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>2016-03-18</td>\n",
       "      <td>megyn-kelly</td>\n",
       "      <td>sick</td>\n",
       "      <td>Everybody should boycott the @megynkelly show....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8040</th>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>michael-bloomberg</td>\n",
       "      <td>bad debate performances</td>\n",
       "      <td>“Ever since (Mini Mike) Bloomberg’s bad debate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>elizabeth-warren</td>\n",
       "      <td>All talk, no action -- maybe her Native Americ...</td>\n",
       "      <td>Goofy Elizabeth Warren is weak and ineffective...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date             target  \\\n",
       "7471 2019-12-12              msnbc   \n",
       "1453 2016-05-28          the-media   \n",
       "1174 2016-03-18        megyn-kelly   \n",
       "8040 2020-03-02  michael-bloomberg   \n",
       "1307 2016-05-07   elizabeth-warren   \n",
       "\n",
       "                                                 insult  \\\n",
       "7471                                          Fake News   \n",
       "1453                                             biased   \n",
       "1174                                               sick   \n",
       "8040                            bad debate performances   \n",
       "1307  All talk, no action -- maybe her Native Americ...   \n",
       "\n",
       "                                                  tweet  \n",
       "7471  It’s great to have a wonderful subject, Presid...  \n",
       "1453  Don't believe the biased and phony media quoti...  \n",
       "1174  Everybody should boycott the @megynkelly show....  \n",
       "8040  “Ever since (Mini Mike) Bloomberg’s bad debate...  \n",
       "1307  Goofy Elizabeth Warren is weak and ineffective...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3ad883",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "import spacy \n",
    "from typing import List\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# TEXT = data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')\n",
    "# LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "# Load model to return language object, note that en is deprecated\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Calling nlp on tweet texts to return a processed doc for each\n",
    "# train_data['tokenized_tweet'] = [nlp(tweet) for tweet in train_data.tweet]\n",
    "# train_data.sample(3)\n",
    "\n",
    "# Create a tokenizer function\n",
    "def tokenizer_en(text: str) -> List[str]:\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]\n",
    "\n",
    "DATE = data.Field()\n",
    "TARGET = data.Field()\n",
    "INSULT = data.Field()\n",
    "TWEET = data.Field(\n",
    "  tokenize    = tokenizer_en,\n",
    "  lower       = True,\n",
    "  batch_first = True,\n",
    "  init_token  = '<bos>',\n",
    "  eos_token   = '<eos>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b483628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.drop('doc', axis=1, inplace=True)\n",
    "# train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ea5ee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['d', 'ta', 'i', 'tw'])\n",
      "dict_values([['2019-12-12'], ['msnbc'], ['Fake', 'News'], ['it', '’s', 'great', 'to', 'have', 'a', 'wonderful', 'subject', ',', 'president', 'trump', '.', 'fake', 'news', 'like', 'cnn', '&', 'msnbc', 'are', 'dying', '.', 'if', 'they', 'treated', 'me', 'fairly', ',', 'they', 'would', 'do', 'well', '.', 'have', 'zero', 'credibility', '!', 'https://t.co/yt8n8dgsco']])\n",
      "{'d': ['2019-12-12'], 'ta': ['msnbc'], 'i': ['Fake', 'News'], 'tw': ['it', '’s', 'great', 'to', 'have', 'a', 'wonderful', 'subject', ',', 'president', 'trump', '.', 'fake', 'news', 'like', 'cnn', '&', 'msnbc', 'are', 'dying', '.', 'if', 'they', 'treated', 'me', 'fairly', ',', 'they', 'would', 'do', 'well', '.', 'have', 'zero', 'credibility', '!', 'https://t.co/yt8n8dgsco']}\n"
     ]
    }
   ],
   "source": [
    "fields = {'date': ('d', DATE), 'target': ('ta', TARGET), 'insult': ('i', INSULT), 'tweet': ('tw', TWEET)}\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'data',\n",
    "                                        train = 'train.csv',\n",
    "                                        validation = 'valid.csv',\n",
    "                                        test = 'test.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = False\n",
    ")\n",
    "\n",
    "print(train_data[0]. __dict__.keys())\n",
    "print(train_data[0]. __dict__.values())\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45053bc3",
   "metadata": {},
   "source": [
    "## Building a Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baf64f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TWEET vocabulary: 9125\n",
      "Unique tokens in TARGET vocabulary: 731\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TWEET.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "TARGET.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "\n",
    "print(f\"Unique tokens in TWEET vocabulary: {len(TWEET.vocab)}\") # addition include <unk> token and <pad> token\n",
    "print(f\"Unique tokens in TARGET vocabulary: {len(TARGET.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8af5a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 11136), (',', 10934), ('.', 9786), ('!', 5892), ('and', 5162), ('to', 4858), ('a', 4274), ('is', 4221), ('of', 3803), ('in', 2901), ('for', 2193), ('that', 2178), ('i', 2078), ('they', 2070), ('are', 1939), ('it', 1865), ('on', 1823), ('he', 1589), ('&', 1567), ('was', 1460)]\n"
     ]
    }
   ],
   "source": [
    "print(TWEET.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f69b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<bos>', '<eos>', 'the', ',', '.', '!', 'and', 'to']\n"
     ]
    }
   ],
   "source": [
    "print(TWEET.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e74e79e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x14f5bf850>>, {'<unk>': 0, '<pad>': 1, 'the-media': 2, 'democrats': 3, 'hillary-clinton': 4, 'trump-russia': 5, 'joe-biden': 6, 'the-new-york-times': 7, 'cnn': 8, 'impeachment-inquiry': 9, 'adam-schiff': 10, 'nancy-pelosi': 11, '2020-election': 12, 'michael-bloomberg': 13, 'washington-post': 14, 'james-comey': 15, 'jeb-bush': 16, 'ted-cruz': 17, 'mueller-team': 18, 'marco-rubio': 19, 'elizabeth-warren': 20, 'fox-news': 21, 'chuck-schumer': 22, 'msnbc': 23, 'obamacare': 24, 'the-fed': 25, 'bernie-sanders': 26, 'barack-obama': 27, 'nbc-news': 28, 'mail-in-voting': 29, 'trump-report': 30, 'john-bolton': 31, 'karl-rove': 32, 'megyn-kelly': 33, 'michael-cohen': 34, 'chuck-todd': 35, 'mitt-romney': 36, 'morning-joe': 37, 'richard-blumenthal': 38, 'andrew-cuomo': 39, 'robert-mueller': 40, 'chris-cuomo': 41, 'fbi': 42, 'twitter': 43, 'brian-kemp': 44, 'andrew-mccabe': 45, 'john-mccain': 46, 'jeff-flake': 47, 'china': 48, 'john-kasich': 49, 'obama-administration': 50, 'joe-scarborough': 51, 'mexico': 52, 'politico': 53, 'bill-deblasio': 54, 'doug-jones': 55, 'iran-deal': 56, 'the-squad': 57, 'us-immigration-policies': 58, 'h1n1-response': 59, 'lindsey-graham': 60, 'omarosa-manigault': 61, 'anthony-scaramucci': 62, 'fox-polls': 63, 'jon-ossoff': 64, 'polls': 65, 'trade-pacts': 66, 'abc-post-poll': 67, 'ben-sasse': 68, 'comcast': 69, 'glenn-beck': 70, 'iran': 71, 'jeff-sessions': 72, 'jerome-powell': 73, 'peter-strzok': 74, 'saturday-night-live': 75, 'tom-steyer': 76, '60-minutes': 77, 'abc-news': 78, 'club-for-growth': 79, 'elijah-cummings': 80, 'macys': 81, 'nafta': 82, 'paul-ryan': 83, 'the-system': 84, 'union-leader': 85, 'united-states': 86, 'wall-street-journal': 87, 'associated-press': 88, 'bob-corker': 89, 'charles-krauthammer': 90, 'delegate-system': 91, 'geoff-duncan': 92, 'john-brennan': 93, 'jon-tester': 94, 'mika-brzezinski': 95, 'ninth-circuit': 96, 'republicans': 97, 'brad-raffensperger': 98, 'department-of-justice': 99, 'george-will': 100, 'nbc': 101, 'pharma-ad': 102, 'politicians': 103, 'pollsters': 104, 'sadiq-khan': 105, 'whca-dinner': 106, 'beto-orourke': 107, 'bill-kristol': 108, 'bill-maher': 109, 'brian-williams': 110, 'chris-wallace': 111, 'conor-lamb': 112, 'democrat-run-cities': 113, 'european-union': 114, 'jeff-zucker': 115, 'jim-mattis': 116, 'kamala-harris': 117, 'maxine-waters': 118, 'ralph-northam': 119, 'rex-tillerson': 120, 'rick-snyder': 121, 'supreme-court': 122, 'ted-wheeler': 123, 'tim-ryan': 124, 'washington-dc': 125, 'amazon': 126, 'bill-clinton': 127, 'cbs': 128, 'des-moines-register': 129, 'dominion-voting': 130, 'elizabeth-beck': 131, 'erick-erickson': 132, 'google': 133, 'ilhan-omar': 134, 'james-robart': 135, 'justin-amash': 136, 'kneeling-nfl-players': 137, 'lisa-page': 138, 'miles-taylor': 139, 'new-york': 140, 'new-york-daily-news': 141, 'nfl': 142, 'paul-krugman': 143, 'steve-bannon': 144, 'woodward-book': 145, 'andrew-gillum': 146, 'carly-fiorina': 147, 'cheri-jacobus': 148, 'democratic-candidates': 149, 'democratic-national-committee': 150, 'donny-deutsch': 151, 'eric-schneiderman': 152, 'eric-swalwell': 153, 'existing-border-wall': 154, 'filibuster-rule': 155, 'george-conway': 156, 'gretchen-whitmer': 157, 'guatemala': 158, 'jacob-frey': 159, 'joe-manchin': 160, 'john-bel-edwards': 161, 'john-kelly': 162, 'koch-brothers': 163, 'ms-13': 164, 'mueller-report': 165, 'national-review': 166, 'nato': 167, 'penn-jillette': 168, 'protesters': 169, 'puerto-rico': 170, 'rashida-tlaib': 171, 'stuart-stevens': 172, 'supreme-court-protestors': 173, 'tim-kaine': 174, 'tom-friedman': 175, 'tony-schwartz': 176, 'vanity-fair': 177, 'bob-vander-plaats': 178, 'brian-ross': 179, 'calif-12': 180, 'carmen-yulin-cruz': 181, 'cnn-panelists': 182, 'dana-nessel': 183, 'danny-o-connor': 184, 'dean-baquet': 185, 'dnc-emails': 186, 'don-lemon': 187, 'donna-brazile': 188, 'el-salvador': 189, 'facebook': 190, 'fire-and-fury': 191, 'forbes': 192, 'frank-luntz': 193, 'frederica-wilson': 194, 'ga-2020-recount': 195, 'gavin-newsom': 196, 'hunter-biden': 197, 'investigations-of-trump-presidency': 198, 'jeffrey-goldberg': 199, 'juan-williams': 200, 'katy-tur': 201, 'late-night-television': 202, 'levar-ball': 203, 'lincoln-project': 204, 'lovely-warren': 205, 'matt-drudge': 206, 'maureen-dowd': 207, 'md-7': 208, 'michael-wolff': 209, 'new-york-sea-wall': 210, 'nicole-wallace': 211, 'republican-candidates': 212, 'rich-lowry': 213, 'richard-cordray': 214, 'rick-perry': 215, 's-e-cupp': 216, 'stacey-abrams': 217, 'steve-schmidt': 218, 'steve-scully': 219, 'the-individual-mandate': 220, 'tim-o-brien': 221, 'uk-ambassador': 222, 'univision': 223, 'us-leaders': 224, 'womens-assault-allegations': 225, '2016-election': 226, 'alec-baldwin': 227, 'alicia-machado': 228, 'andrew-weissmann': 229, 'bashar-al-assad': 230, 'ben-carson': 231, 'big-tech': 232, 'bob-casey': 233, 'ca-25-election': 234, 'california': 235, 'carl-bernstein': 236, 'cdc': 237, 'chain-migration': 238, 'chemical-attack-syria': 239, 'chicago': 240, 'christopher-steele': 241, 'claire-mccaskill': 242, 'cliff-sims': 243, 'cnbc': 244, 'colin-powell': 245, 'comey-memos': 246, 'commission-on-presidential-debates': 247, 'coronavirus': 248, 'cory-booker': 249, 'cruz-kasich-pact': 250, 'dave-weigel': 251, 'david-brooks': 252, 'deb-sopan': 253, 'decision-to-halt-the-ban': 254, 'democratic-national-convention': 255, 'democrats-nunes-memo': 256, 'donna-shalala': 257, 'drudge-report': 258, 'face-the-nation': 259, 'george-pataki': 260, 'gonzalo-curiel': 261, 'harry-reid': 262, 'iowa-caucus-2020': 263, 'isis': 264, 'john-kerry': 265, 'john-lewis': 266, 'john-sununu': 267, 'jussie-smollet': 268, 'katie-couric': 269, 'kim-jong-un': 270, 'kweisi-mfume': 271, 'lawrence-o-donnell': 272, 'lester-holt': 273, 'mark-sanford': 274, 'mary-trump': 275, 'max-rose': 276, 'mayor-pete': 277, 'meet-the-press': 278, 'michael-moore-show': 279, 'michelle-wolf': 280, 'muriel-bowser': 281, 'north-korea': 282, 'paris-agreement': 283, 'peggy-noonan': 284, 'pundits': 285, 'rand-paul': 286, 'richard-trumka': 287, 'rick-bright': 288, 'robert-gates': 289, 'sally-yates': 290, 'scott-walker': 291, 'seth-meyers': 292, 'spygate': 293, 'stanley-mcchrystal': 294, 'tom-ridge': 295, 'travel-ban': 296, 'whoopi-goldberg': 297, 'wsj-nbc-poll': 298, 'al-schmidt': 299, 'alexander-vindman': 300, 'alleged-nyc-terrorist': 301, 'amy-chozick': 302, 'anthony-weiner': 303, 'anti-trump-ads': 304, 'antifa': 305, 'arnold-schwarzenegger': 306, 'baltimore': 307, 'bette-midler': 308, 'bill-nelson': 309, 'blm-protesters': 310, 'bob-woodward': 311, 'brit-hume': 312, 'brussels': 313, 'california-train-project': 314, 'caravans': 315, 'carl-cameron': 316, 'catch-and-release': 317, 'cfpb': 318, 'charles-koch': 319, 'chelsea-manning': 320, 'chris-hahn': 321, 'clare-o-connor': 322, 'clinton-foundation': 323, 'colin-kaepernick': 324, 'congress': 325, 'daca-kids': 326, 'david-green': 327, 'david-gregory': 328, 'debate-microphone': 329, 'debbie-dingell': 330, 'debbie-stabenow': 331, 'debra-messing': 332, 'detroit': 333, 'dick-durbin': 334, 'doug-ducey': 335, 'espn': 336, 'fda': 337, 'firefighters-union': 338, 'florida-early-voting': 339, 'fox-news-debate': 340, 'freedom-caucus': 341, 'general-motors': 342, 'george-w-bush': 343, 'germany': 344, 'graydon-carter': 345, 'green-new-deal': 346, 'harley-davidson': 347, 'hollywood': 348, 'honduras': 349, 'house-democrats': 350, 'jackson-lee': 351, 'james-clapper': 352, 'jay-inslee': 353, 'jeb-bush-campaign': 354, 'jeff-horwitz': 355, 'jennifer-rubin': 356, 'jim-acosta': 357, 'jimmy-kimmel': 358, 'joe-walsh': 359, 'john-dean': 360, 'john-harwood': 361, 'john-hickenlooper': 362, 'john-thune': 363, 'jonathan-martin': 364, 'joy-ann-reid': 365, 'juaquin-castro': 366, 'kate-steinle-verdict': 367, 'kirsten-gillibrand': 368, 'kyrsten-sinema': 369, 'larry-hogan': 370, 'larry-sabato': 371, 'lesley-stahl': 372, 'los-angeles': 373, 'losers-haters': 374, 'major-garrett': 375, 'mark-warner': 376, 'marshawn-lynch': 377, 'matthew-dowd': 378, 'meghan-mccain': 379, 'michael-barbaro': 380, 'michael-nutter': 381, 'middle-east-relations': 382, 'mort-zuckerman': 383, 'nba': 384, 'nbc-executives': 385, 'nbc-nightly-news': 386, 'new-york-city': 387, 'norah-o-donnell': 388, 'nytimes-article': 389, 'oprah-winfrey': 390, 'pakistan': 391, 'pete-ricketts': 392, 'peter-baker': 393, 'philip-rucker': 394, 'political-ads': 395, 'portland': 396, 'pramila-jayapal': 397, 'rage-book': 398, 'recounts-in-florida': 399, 'repub-presidential-primary-challengers-2020': 400, 'rnc': 401, 'roger-goodell': 402, 'roger-stone-sentence': 403, 'russia': 404, 'russia-bounty-story': 405, 'ruth-bader-ginsburg': 406, 'ruth-marcus': 407, 'samuel-l-jackson': 408, 'scotus-rally': 409, 'seal-prosecutors': 410, 'seattle-portland-protesters': 411, 'section-230': 412, 'shephard-smith': 413, 'small-wall-section': 414, 'social-media': 415, 'spike-lee': 416, 'state-of-the-union': 417, 'states-with-dem-governors': 418, 'stephen-sisolak': 419, 'stone-juror': 420, 'supporters-of-middle-east-wars': 421, 'tallahassee': 422, 'ted-cruz-campaign': 423, 'the-oscars': 424, 'the-red-hen': 425, 'the-republican-establishment': 426, 'the-room-where-it-happened': 427, 'the-view': 428, 'today-show': 429, 'tpp-deal': 430, 'trump-opposition': 431, 'ucla-basketball-players': 432, 'united-nations': 433, 'usps': 434, 'veronica-escobar': 435, 'wall-of-moms': 436, 'water-lanes': 437, 'weekly-standard': 438, 'world-trade-organization': 439, '2020-dem-candidates': 440, '2020-pres-debate??': 441, '???': 442, 'a-b-stoddard': 443, 'aaron-zebley': 444, 'abc-politics': 445, 'afl-cio': 446, 'al-franken': 447, 'ali-khamenei': 448, 'ana-navarro': 449, 'anderson-cooper': 450, 'andrew-napolitano': 451, 'andy-lack': 452, 'angela-merkel': 453, 'anna-wintour': 454, 'anthony-brindisi': 455, 'anthony-fauci': 456, 'aoc': 457, 'arianna-huffington': 458, 'ashley-parker': 459, 'atlanta': 460, 'auto-executives': 461, 'bad-deals': 462, 'bakari-sellers': 463, 'barbara-res': 464, 'ben-schreckenger': 465, 'benghazi-hearings': 466, 'bernard-goldberg': 467, 'bias-free-language-guide': 468, 'biden-ad': 469, 'biden-administration': 470, 'biden-family': 471, 'biden-staff': 472, 'big-game-hunting': 473, 'bitcoin': 474, 'blm': 475, 'bloomberg-news': 476, 'bob-iger': 477, 'bobby-jindal': 478, 'books-critical-of-president-trump': 479, 'boston-globe': 480, 'bowe-bergdahl-decision': 481, 'brenda-snipes': 482, 'bret-stephens': 483, 'brett-mcgurk': 484, 'brian-stelter': 485, 'bruce-ohr': 486, 'buzzfeed': 487, 'ca-28': 488, 'california-cars': 489, 'california-environmental-laws': 490, 'california-water-use': 491, 'carter-page-fisa': 492, 'charles-blow': 493, 'charlie-baker': 494, 'chris-krebs': 495, 'chris-stirewalt': 496, 'chrissy-teigen': 497, 'christianity-today': 498, 'chuck-jones': 499, 'civil-war-memorial-opponents': 500, 'cnn-trump-documentary': 501, 'cokie-roberts': 502, 'collin-peterson': 503, 'comcast-executives': 504, 'common-core': 505, 'cooper-governor': 506, 'daily-beast': 507, 'dan-henninger': 508, 'dan-mccready': 509, 'dana-perino': 510, 'dave-roberts': 511, 'david-cay-johnston': 512, 'david-kris': 513, 'dc-leaders?': 514, 'dc-police': 515, 'debates': 516, 'debbie-wasserman-schultz': 517, 'decision-to-disqualify-horse': 518, 'democratic-debate-july-30': 519, 'democratic-house-committee': 520, 'dianne-feinstein': 521, 'dnc': 522, 'don-mcgahn': 523, 'drug-cartels': 524, 'elites': 525, 'email-investigation': 526, 'emmanuel-macron': 527, 'emmys-2017': 528, 'endless-wars': 529, 'epi-pens': 530, 'erin-burnett': 531, 'errol-louis': 532, 'establishment': 533, 'european-leaders': 534, 'f35-program': 535, 'fbi-investigation-of-hillary': 536, 'fbi-investigation-of-hillarys-emails': 537, 'first-100-days': 538, 'fortune-magazine': 539, 'fox-news-polls': 540, 'fox-news-sunday': 541, 'frank-vandersloot': 542, 'full-frontal': 543, 'fusion-gps': 544, 'george-h-w-bush': 545, 'george-papadopolous': 546, 'gillian-turner': 547, 'gitmo-prisoner-release': 548, 'goodyear-tires': 549, 'gustavo-petro': 550, 'hallie-jackson': 551, 'hamilton-cast': 552, 'harley-rouda': 553, 'harry-hurt': 554, 'haywood-s-gilliam': 555, 'headline': 556, 'howard-schultz': 557, 'huffington-post': 558, 'huma-abedin': 559, 'hunter-bidens-laptop': 560, 'ig-report': 561, 'illegal-immigration': 562, 'illegal-leaks': 563, 'internal-revenue-service': 564, 'iowa-democratic-party': 565, 'jake-tapper': 566, 'james-clyburn': 567, 'jamie-dimon': 568, 'jamie-weinstein': 569, 'jeff-bezos': 570, 'jeff-zeleny': 571, 'jerry-brown': 572, 'jill-colvin': 573, 'jimmy-fallon': 574, 'jobs-report': 575, 'jocelyn-benson': 576, 'joe-crowley': 577, 'joe-cunningham': 578, 'joe-donnely': 579, 'joe-mcquaid': 580, 'john-allen': 581, 'john-huber': 582, 'john-kasichs-ad-guy': 583, 'john-king': 584, 'john-legere': 585, 'john-podesta': 586, 'john-roberts': 587, 'jonathan-karl': 588, 'julian-castro': 589, 'justin-trudeau': 590, 'karen-bass': 591, 'kasie-hunt': 592, 'kate-brown': 593, 'kathy-griffin': 594, 'katie-rogers': 595, 'ken-frazier': 596, 'late-night-television-hosts': 597, 'laurene-powell-jobs': 598, 'laws-about-sanctuary-cities': 599, 'leakers': 600, 'letitia-james': 601, 'lincoln-chafee': 602, 'lisa-belkin': 603, 'lois-frankel': 604, 'london': 605, 'loretta-lynch': 606, 'maggie-haberman': 607, 'manafort-sentence': 608, 'manufacturing-ceos': 609, 'marc-elias': 610, 'marc-thiessen': 611, 'mark-cuban': 612, 'mark-herring': 613, 'martin-o-malley': 614, 'marty-walsh': 615, 'matt-bai': 616, 'mccabe-memos': 617, 'merck-pharma': 618, 'meryl-streep': 619, 'michael-avenatti': 620, 'michael-deantonio': 621, 'michael-flynn-case': 622, 'michael-morell': 623, 'mikie-sherrill': 624, 'milwaukee': 625, 'mitch-mcconnell': 626, 'nascar': 627, 'nc-ballot-extension': 628, 'neil-young': 629, 'nellie-ohr': 630, 'nevada': 631, 'never-trumpers': 632, 'new-day': 633, 'new-york-democrats': 634, 'nikki-haley': 635, 'nsa': 636, 'obamagate': 637, 'opec': 638, 'oreilly-factor': 639, 'our-visa-system': 640, 'oval-office-podium': 641, 'past-presidential-administrations': 642, 'pat-toomey': 643, 'paul-begala': 644, 'paulina-vega': 645, 'people': 646, 'pfizer': 647, 'philip-mudd': 648, 'pledge-of-allegiance-decision-slp': 649, 'politically-correct-fools': 650, 'polling-establishment': 651, 'presidential-candidates': 652, 'prince-alwaleed-bin-talal': 653, 'puerto-ricans': 654, 'puerto-rico-aid-relief': 655, 'rachel-maddow': 656, 'refugee-crisis-in-europe': 657, 'refugees-in-germany': 658, 'rexnord': 659, 'rick-scott': 660, 'rick-wilson': 661, 'robert-deniro': 662, 'rockin-in-the-free-world': 663, 'rod-rosenstein': 664, 'rodrigo-duterte': 665, 'ruth-marcus-book': 666, 'sam-nunberg': 667, 'samantha-bee': 668, 'san-francisco': 669, 'sanctuary-cities': 670, 'sarah-jeong': 671, 'schiff-memo': 672, 'senate-democrats': 673, 'senate-republicans': 674, 'sherrod-brown': 675, 'snoop-dogg': 676, 'southern-border': 677, 'special-interests': 678, 'state-department': 679, 'states-refusing-to-give-voter-panel-info': 680, 'stefan-lofven': 681, 'stephanie-rawlings-blake': 682, 'stephen-colbert': 683, 'stephen-hahn': 684, 'steve-kerr': 685, 'stormy-daniels-alleged-assailant': 686, 'strzok-page-texts': 687, 'super-pacs': 688, 'sweden': 689, 't-mobile': 690, 'team-of-vipers': 691, 'terrorists': 692, 'the-atlantic': 693, 'the-courts': 694, 'the-new-yorker': 695, 'theresa-greenfield': 696, 'theresa-may': 697, 'thomas-frieden': 698, 'thomas-massie': 699, 'tony-podesta': 700, 'town-hall-meetings': 701, 'trumps-taxes': 702, 'truth-lies-leadership': 703, 'tsa': 704, 'uk-health-system': 705, 'undocumented-immigrants': 706, 'us-australia-refugee-deal': 707, 'us-census': 708, 'us-court-system': 709, 'us-government': 710, 'us-korea-military-exercises': 711, 'us-legal-system': 712, 'us-mexico-trade-surplus': 713, 'vandals-in-nc': 714, 'very-stable-genius': 715, 'veterans-affairs': 716, 'virginia-economy': 717, 'virginia-republican-party': 718, 'virtual-learning': 719, 'vladimir-putin': 720, 'vote-count-michigan': 721, 'washington-insiders': 722, 'whistleblower-complaint': 723, 'william-weld': 724, 'willie-geist': 725, 'wisconsin-recount': 726, 'world-news-tonight': 727, 'wreath-cancellation-policy': 728, 'wsj-editorial-board': 729, 'yoel-roth': 730})\n"
     ]
    }
   ],
   "source": [
    "print(TARGET.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9babf9",
   "metadata": {},
   "source": [
    "## Constructing the Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bbf6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# pytorch boilerplate that determines whether a GPU is present or not,\n",
    "# this determines whether the dataset or model can to moved to a GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83c1e4",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea1e5f",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f52159f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Additional info on word embeddings\n",
    "# https://monkeylearn.com/blog/word-embeddings-transform-text-numbers/\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):  # three layers are an embedding layer, RNN, and a linear layer \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3506905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
